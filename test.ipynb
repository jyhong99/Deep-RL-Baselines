{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Gym version v0.24.1 has a number of critical issues with `gym.make` such that environment observation and action spaces are incorrectly evaluated, raising incorrect errors and warning . It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n",
      "c:\\Users\\ppp1j\\AppData\\Local\\anaconda3\\envs\\pytorch\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:69: UserWarning: \u001b[33mWARN: Agent's minimum action space value is -infinity. This is probably too low.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\ppp1j\\AppData\\Local\\anaconda3\\envs\\pytorch\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:73: UserWarning: \u001b[33mWARN: Agent's maximum action space value is infinity. This is probably too high\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\ppp1j\\AppData\\Local\\anaconda3\\envs\\pytorch\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================+=====================================\n",
      "TRAINING STARTING TIME      | 2024-11-01 13:26:42\n",
      "PROJECT NAME                | HalfCheetah-v4\n",
      "ENVIRONMENT                 | <TimeLimit<OrderEnforcing<PassiveEnvChecker<HalfCheetahEnv<HalfCheetah-v4>>>>>\n",
      "EVALUATION ENVIRONMENT      | <TimeLimit<OrderEnforcing<PassiveEnvChecker<HalfCheetahEnv instance>>>>\n",
      "AGENT                       | <baselines.agent.policy_based.on_policy.ppo.PPO object at 0x0000022C8A8DBFA0>\n",
      "SEED                        | 0\n",
      "NORMALIZED ENVIRONMENT      | True\n",
      "TOTAL TRAINING TIMESTEPS    | 1000000\n",
      "THE NUMBER OF RUNNERS       | 8\n",
      "ITERATIONS PER A RUNNER     | 100\n",
      "EVALUATION MODE             | True\n",
      "EVALUATION INTERVALS        | 10000\n",
      "EVALUATION ITERATIONS       | 10\n",
      "LOAD PATH                   | None\n",
      "============================+=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-01 13:26:46,616\tINFO worker.py:1783 -- Started a local Ray instance.\n",
      "\u001b[36m(pid=25304)\u001b[0m Warning: Gym version v0.24.1 has a number of critical issues with `gym.make` such that environment observation and action spaces are incorrectly evaluated, raising incorrect errors and warning . It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================== TRAINING HAS BEEN SHUTDOWN =====================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=8100)\u001b[0m Warning: Gym version v0.24.1 has a number of critical issues with `gym.make` such that environment observation and action spaces are incorrectly evaluated, raising incorrect errors and warning . It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\u001b[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================+=================================\n",
      "TRINING FINISHING TIME      | 2024-11-01 13:27:00\n",
      "TOTAL TRAINIMG ELAPSE       | 0h 0m 17s\n",
      "============================+=================================\n",
      "Logger data is empty. No data to plot.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of rows must be a positive integer, not 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(env_name)\n\u001b[0;32m      7\u001b[0m agent \u001b[38;5;241m=\u001b[39m PPO(env, reward_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, adv_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_runners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunner_iters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_intervals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ppp1j\\Desktop\\Deep RL Baselines\\baselines\\common\\policy.py:95\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.train\u001b[1;34m(self, project_name, **config)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_runners \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m DistributedTrainer(\n\u001b[0;32m     89\u001b[0m         env\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, \n\u001b[0;32m     90\u001b[0m         eval_env\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_env, \n\u001b[0;32m     91\u001b[0m         agent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \n\u001b[0;32m     92\u001b[0m         seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed, \n\u001b[0;32m     93\u001b[0m         )\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalized_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_runners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_runners\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrunner_iters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunner_iters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_intervals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_intervals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_iters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_iters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_graphs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_graphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m    111\u001b[0m         env\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, \n\u001b[0;32m    112\u001b[0m         eval_env\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_env, \n\u001b[0;32m    113\u001b[0m         agent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \n\u001b[0;32m    114\u001b[0m         seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed, \n\u001b[0;32m    115\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\ppp1j\\Desktop\\Deep RL Baselines\\baselines\\common\\train.py:542\u001b[0m, in \u001b[0;36mDistributedTrainer.train\u001b[1;34m(self, project_name, load_path, normalized_env, max_iters, n_runners, runner_iters, eval_mode, eval_intervals, eval_iters, policy_type, show_stats, show_graphs)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_logs()\n\u001b[0;32m    541\u001b[0m plot_train_result(project_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_logger, window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, show_graphs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_graphs)\n\u001b[1;32m--> 542\u001b[0m \u001b[43mplot_epoch_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_logger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_graphs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_graphs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ppp1j\\Desktop\\Deep RL Baselines\\baselines\\common\\plot.py:102\u001b[0m, in \u001b[0;36mplot_epoch_result\u001b[1;34m(project_name, epoch_logger, window, show_graphs)\u001b[0m\n\u001b[0;32m    100\u001b[0m num_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(result_keys)\n\u001b[0;32m    101\u001b[0m num_rows \u001b[38;5;241m=\u001b[39m num_metrics\n\u001b[1;32m--> 102\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubplots\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_rows\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_metrics \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    105\u001b[0m     axs \u001b[38;5;241m=\u001b[39m [axs]\n",
      "File \u001b[1;32mc:\\Users\\ppp1j\\AppData\\Local\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\pyplot.py:1760\u001b[0m, in \u001b[0;36msubplots\u001b[1;34m(nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw, **fig_kw)\u001b[0m\n\u001b[0;32m   1615\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1616\u001b[0m \u001b[38;5;124;03mCreate a figure and a set of subplots.\u001b[39;00m\n\u001b[0;32m   1617\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \n\u001b[0;32m   1758\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m fig \u001b[38;5;241m=\u001b[39m figure(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfig_kw)\n\u001b[1;32m-> 1760\u001b[0m axs \u001b[38;5;241m=\u001b[39m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubplots\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1761\u001b[0m \u001b[43m                   \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubplot_kw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubplot_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1762\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mgridspec_kw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgridspec_kw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight_ratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight_ratios\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1763\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mwidth_ratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth_ratios\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fig, axs\n",
      "File \u001b[1;32mc:\\Users\\ppp1j\\AppData\\Local\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\figure.py:860\u001b[0m, in \u001b[0;36mFigureBase.subplots\u001b[1;34m(self, nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw)\u001b[0m\n\u001b[0;32m    856\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth_ratios\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must not be defined both as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    857\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter and as key in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgridspec_kw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    858\u001b[0m     gridspec_kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth_ratios\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m width_ratios\n\u001b[1;32m--> 860\u001b[0m gs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_gridspec(nrows, ncols, figure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgridspec_kw)\n\u001b[0;32m    861\u001b[0m axs \u001b[38;5;241m=\u001b[39m gs\u001b[38;5;241m.\u001b[39msubplots(sharex\u001b[38;5;241m=\u001b[39msharex, sharey\u001b[38;5;241m=\u001b[39msharey, squeeze\u001b[38;5;241m=\u001b[39msqueeze,\n\u001b[0;32m    862\u001b[0m                   subplot_kw\u001b[38;5;241m=\u001b[39msubplot_kw)\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m axs\n",
      "File \u001b[1;32mc:\\Users\\ppp1j\\AppData\\Local\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\figure.py:1538\u001b[0m, in \u001b[0;36mFigureBase.add_gridspec\u001b[1;34m(self, nrows, ncols, **kwargs)\u001b[0m\n\u001b[0;32m   1495\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;124;03mLow-level API for creating a `.GridSpec` that has this figure as a parent.\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1534\u001b[0m \n\u001b[0;32m   1535\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m _ \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# pop in case user has added this...\u001b[39;00m\n\u001b[1;32m-> 1538\u001b[0m gs \u001b[38;5;241m=\u001b[39m GridSpec(nrows\u001b[38;5;241m=\u001b[39mnrows, ncols\u001b[38;5;241m=\u001b[39mncols, figure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gs\n",
      "File \u001b[1;32mc:\\Users\\ppp1j\\AppData\\Local\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\gridspec.py:363\u001b[0m, in \u001b[0;36mGridSpec.__init__\u001b[1;34m(self, nrows, ncols, figure, left, bottom, right, top, wspace, hspace, width_ratios, height_ratios)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhspace \u001b[38;5;241m=\u001b[39m hspace\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure \u001b[38;5;241m=\u001b[39m figure\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mwidth_ratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth_ratios\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mheight_ratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight_ratios\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ppp1j\\AppData\\Local\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\gridspec.py:48\u001b[0m, in \u001b[0;36mGridSpecBase.__init__\u001b[1;34m(self, nrows, ncols, height_ratios, width_ratios)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m----------\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m    If not given, all rows will have the same height.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(nrows, Integral) \u001b[38;5;129;01mor\u001b[39;00m nrows \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of rows must be a positive integer, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnrows\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ncols, Integral) \u001b[38;5;129;01mor\u001b[39;00m ncols \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of columns must be a positive integer, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mncols\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Number of rows must be a positive integer, not 0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x0 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "from baselines.agent.policy_based.on_policy.ppo import PPO\n",
    "from baselines.agent.policy_based.off_policy.ddpg import DDPG\n",
    "\n",
    "env_name = 'HalfCheetah-v4'\n",
    "env = gym.make(env_name)\n",
    "agent = PPO(env, reward_norm=True, adv_norm=True)\n",
    "agent.train(env_name, normalized_env=True, max_iters=1000000, n_runners=8, runner_iters=100, eval_intervals=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
